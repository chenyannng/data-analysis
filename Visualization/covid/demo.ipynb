{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitgeoconda2340ae9055894de88542012ce4b20df7",
   "display_name": "Python 3.7.6 64-bit ('geo': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo for visualizing COVID-19 pandemic dataset from Johns Hopkins CSSE : https://github.com/CSSEGISandData/COVID-19\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReadData import ReadData\n",
    "from DictName import DictName\n",
    "import urllib3\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import geoplot\n",
    "import mapclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from the github repo (data_url) and save to data_path\n",
    "def download_data(data_path, data_url, verbose=1):\n",
    "    http = urllib3.PoolManager()\n",
    "    if verbose > 0:\n",
    "        print('Downloading data file to ' + data_path + ' ...')\n",
    "        with http.request('GET', data_url, preload_content=False) as resp, open('./', 'wb') as out:\n",
    "            shutil.copyfileobj(resp, out)\n",
    "        out.close()\n",
    "        print('... done downloading data!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download global data from github url\n",
    "data_path = './git_data/'\n",
    "data_url_root = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "filetypes = ['confirmed', 'deaths', 'recovered']\n",
    "downloads = {}\n",
    "\n",
    "for f in filetypes:\n",
    "    downloads[f] = data_url_root + 'time_series_covid19_' + f + '_global.csv' \n",
    "\n",
    "if 0:\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    for f in downloads.keys():\n",
    "        save_path = data_path + f + '.csv'\n",
    "        url = downloads[f]\n",
    "        download_data(data_path, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local data\n",
    "\n",
    "def read_file(read_path):\n",
    "    d = ReadData(read_path)\n",
    "    data = d.data\n",
    "    data_country = data.drop(columns=['Lat', 'Long'])\n",
    "    data_country =  data_country.groupby('Country/Region', axis=0).sum()\n",
    "    coordinates = data.loc[:, ['Country/Region', 'Lat', 'Long']]\n",
    "    # coordinates = coordinates.groupby('Country/Region').median()\n",
    "    data_dict = {'metric': data_country,\n",
    "                'coordinates': coordinates}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def plot_time_series(data, fig_params):\n",
    "    country_list = data.index\n",
    "    legend_items = []\n",
    "    fig, axis = plt.subplots()\n",
    "    for c in country_list:\n",
    "        y = data.loc[c]        \n",
    "        y = y[y>=100]\n",
    "        x = np.array(range(1, len(y)+1))  \n",
    "        legend_items.append(c)\n",
    "        axis.plot(x, y)\n",
    "    axis.legend(legend_items)\n",
    "    axis.set_xlabel(fig_params['xlabel'])\n",
    "    axis.set_ylabel(fig_params['ylabel'])\n",
    "    axis.set_yscale(fig_params['yscale'])\n",
    "\n",
    "\n",
    "\n",
    "# Store data in dictionary\n",
    "data_dict = {}\n",
    "for ft in filetypes:\n",
    "    path = data_path + ft + '.csv'\n",
    "    data_dict[ft] = read_file(path)\n",
    "\n",
    "confirmed = data_dict['confirmed']['metric']\n",
    "deaths = data_dict['deaths']['metric']\n",
    "\n",
    "\n",
    "# Plot confirmed cases in countries with confirmed cases > criteria on the last day\n",
    "fig_params={'xlabel':'Days after confirmed cases > 100',\n",
    "            'ylabel':'Number of cases',\n",
    "            'yscale':'log'}\n",
    "lastday = np.array(confirmed.keys())[-1]\n",
    "confirmed_to_plot = confirmed[confirmed[lastday]>=20000]\n",
    "deaths_to_plot = [] \n",
    "\n",
    "plot_time_series(confirmed_to_plot, fig_params)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate countries' daily accumulated confirmed cases and show on world map\n",
    "def daily_data(data, cgeo, cdata, thisday):\n",
    "    geo_confirm = np.zeros(cgeo.shape)\n",
    "    for i, c in enumerate(cgeo):\n",
    "        if c in cdata:\n",
    "            case = data.loc[c, thisday]\n",
    "            \n",
    "        elif c in DictName.keys():\n",
    "            # print('found',c, 'in dict') \n",
    "            case = data.loc[DictName[c][0], thisday]\n",
    "        else:\n",
    "            case = 0\n",
    "\n",
    "        if case == 0:\n",
    "            geo_confirm[i] = 0\n",
    "        else:    \n",
    "            geo_confirm[i] = np.log10(case)\n",
    "            # geo_confirm[i] = case\n",
    "    return geo_confirm\n",
    "\n",
    "# Get data from geopandas\n",
    "world = geopandas.read_file(\n",
    "    geopandas.datasets.get_path('naturalearth_lowres')\n",
    ")\n",
    "cgeo = np.array(world['name']) # country list from geopandas\n",
    "cdata = np.array(data_dict['confirmed']['coordinates']['Country/Region'].unique()) # country list from dataset\n",
    "data = data_dict['confirmed']['metric']\n",
    "list_dates = np.array(data.keys())\n",
    "last_day = list_dates[-1]\n",
    "\n",
    "# use the last day's data as upper and lower limits for coloring polygons\n",
    "geo_limits = daily_data(data, cgeo, cdata, list_dates[-1])\n",
    "\n",
    "for i, day in enumerate(list_dates):\n",
    "    img_path = './image/%03i'%i + '.png'\n",
    "    geo_confirm = daily_data(data, cgeo, cdata, day)\n",
    "    # scheme = mapclassify.EqualInterval(geo_limits, k=6)\n",
    "    scheme = mapclassify.UserDefined(geo_limits, bins = np.arange(1, np.ceil(np.max(geo_limits))))\n",
    "    geoplot.choropleth(\n",
    "        world, hue=geo_confirm, scheme=scheme,\n",
    "        legend=True, \n",
    "        legend_values=[0, 1, 2, 3, 4, 5],\n",
    "        legend_labels=['<10', '(10,10^2]', '(10^2,10^3]', '(10^3,10^4]', '10^4,10^5', '>10^5'],\n",
    "        legend_kwargs={'loc': 'lower left', 'bbox_to_anchor':(0., 0., 0.1, 0.3),'fontsize':8, 'title':'N confirmed cases',\n",
    "        },\n",
    "        cmap='Greens', figsize=(8, 5)\n",
    "    )\n",
    "    plt.title(day)\n",
    "    \n",
    "    if i<2:\n",
    "        plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under bash use command \"convert -delay 10 -loop 1 *.png m.gif\"\n",
    "# show saved .gif\n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"./image/m.gif\">')"
   ]
  }
 ]
}